# Relations

## 4.1. Ordered Pairs and Cartesian Products

Section 4.1 of *How To Prove It* defines the *Cartesian product* $A \times B$ of two sets $A$ and $B$ to be the set of all ordered pairs $(a, b)$, where $a \in A$ and $b \in B$.  However, in Lean, Cartesian product is an operation on *types*, not sets.  If `A` and `B` are types, then `A × B` is the type of ordered pairs `(a, b)`, where `a` has type `A` and `b` has type `B`.  In other words, if you have `a : A` and `b : B`, then `(a, b)` is an object of type `A × B`.  There is also notation for the first and second coordinates of an ordered pair.  If `p` has type `A × B`, then `p.1` is the first coordinate of `p`, and `p.2` is the second coordinate.  You can also use the notation `p.fst` for the first coordinate of `p` and `p.snd` for the second coordinate.  This means that `p = (p.1, p.2) = (p.fst, p.snd)`.

## 4.2. Relations

Section 4.2 of *HTPI* defines a *relation from $A$ to $B$* to be a subset of $A \times B$.  In other words, if $R$ is a relation from $A$ to $B$, then $R$ is a set whose element are ordered pairs $(a, b)$, where $a \in A$ and $b \in B$.  We will see in the next section that in Lean, it is convenient to use a somewhat different definition of relations.  Nevertheless, we will take some time in this section to study sets of ordered pairs.  If `A` and `B` are types, and `R` has type `Set (A × B)`, then `R` is a set whose elements are ordered pairs `(a, b)`, where `a` has type `A` and `b` has type `B`.

Section 4.2 of *HTPI* discusses several concepts concerning relations.  Here is how these concepts are defined in *HTPI*:

::: {.ndfn arguments="Definition 4.2.3"}
Suppose $R$ is a relation from $A$ to $B$.  Then the *domain* of $R$ is the set

::: {.quote}
$\text{Dom}(R) = \{a \in A \mid \exists b \in B((a, b) \in R)\}$.
:::

The *range* of $R$ is the set

::: {.quote}
$\text{Ran}(R) = \{b \in B \mid \exists a \in A((a, b) \in R)\}$.
:::

The *inverse* of $R$ is the relation $R^{-1}$ from $B$ to $A$ define as follows:

::: {.quote}
$R^{-1} = \{(b, a) \in B \times A \mid (a, b) \in R\}$.
:::

Finally, suppose $R$ is a relation from $A$ to $B$ and $S$ is a relation from $B$ to $C$.  Then the *composition* of $S$ and $R$ is the relation $S \circ R$ from $A$ to $C$ defined as follows:

::: {.quote}
$S \circ R = \{(a, c) \in A \times C \mid \exists b \in B((a, b) \in R \text{ and } (b, c) \in S)\}$.
:::
:::

There are several examples in *HTPI* that illustrate these definitions.  We will focus here on seeing how to work with these concepts in Lean.

We can write corresponding definitions in Lean as follows:

```lean
def Dom {A B : Type} (R : Set (A × B)) : Set A :=
    { a : A | ∃ (b : B), (a, b) ∈ R }
def Ran {A B : Type} (R : Set (A × B)) : Set B :=
    { b : B | ∃ (a : A), (a, b) ∈ R }
def inv {A B : Type} (R : Set (A × B)) : Set (B × A) :=
    { (b, a) : B × A | (a, b) ∈ R }
def comp {A B C : Type} (S : Set (B × C)) (R : Set (A × B)) :
    Set (A × C) := { (a, c) : A × C | ∃ (x : B), (a, x) ∈ R ∧ (x, c) ∈ S }
```

Definitions in Lean are introduced with the keyword `def`.  In the definition of `Dom`, we have declared that `A` and `B` are implicit arguments and `R` is an explicit argument.  That means that, in a Lean file containing these definitions, if we have `R : Set (A × B)`, then we can just write `Dom R` for the domain of `R`, and Lean will figure out for itself what `A` and `B` are.  After the list of arguments there is a colon and then the type of `Dom R`, which is `Set A`.  This is followed by `:=` and then the definition of `Dom R`.  The definition says that `Dom R` is the set of all objects `a` of type `A` such that there is some `b` of type `B` with `(a, b) ∈ R`.  This is a direct translation, into Lean's type-theory language, of the first part of Definition 4.2.3.  The other three definitions are similar; they define `Ran R` to be the range of `R`, `inv R` to be the inverse of `R`, and `comp S R` to be the composition of `S` and `R`.

Here is the main theorem about these concepts, as stated in *HTPI*:

::: {.nthm arguments="Theorem 4.2.5"}
Suppose $R$ is a relation from $A$ to $B$, $S$ is a relation from $B$ to $C$, and $T$ is a relation from $C$ to $D$.  Then:

1.  $(R^{-1})^{-1} = R$.
2.  $\mathrm{Dom}(R^{-1}) = \mathrm{Ran}(R)$.
3.  $\mathrm{Ran}(R^{-1}) = \mathrm{Dom}(R)$.
4.  $T \circ (S \circ R) = (T \circ S) \circ R$.
5.  $(S \circ R)^{-1} = R^{-1} \circ S^{-1}$.
:::

All five parts of this theorem follow directly from the definitions of the relevant concepts.  In fact, in the first three parts, Lean recognizes the two sides of the equation as being definitionally equal, and therefore the tactic `rfl` proves those parts:

```lean
theorem Theorem_4_2_5_1 {A B : Type}
    (R : Set (A × B)) : inv (inv R) = R := by rfl

theorem Theorem_4_2_5_2 {A B : Type}
    (R : Set (A × B)) : Dom (inv R) = Ran R := by rfl

theorem Theorem_4_2_5_3 {A B : Type}
    (R : Set (A × B)) : Ran (inv R) = Dom R := by rfl
```

The fourth part will take a little more work to prove.  We start the proof like this:

```lean
theorem Theorem_4_2_5_4 {A B C D : Type}
    (R : Set (A × B)) (S : Set (B × C)) (T : Set (C × D)) :
    comp T (comp S R) = comp (comp T S) R := by
  apply Set.ext
  fix (a, d) : A × D
```

After the `apply Set.ext` tactic, the goal is

::: {.quote}
`∀ (x : A × D), x ∈ comp T (comp S R) ↔ x ∈ comp (comp T S) R`
:::

The next step should be to introduce an arbitrary object of type `A × D`.  We could just call this object `x`, but Lean let's us use a shortcut here.  An object of type `A × D` must have the form of an ordered pair, where the first coordinate has type `A` and the second has type `D`.  So Lean let's us write it as an ordered pair right away.  That's what we've done in the second step, `fix (a, d) : A × D`.  This tactic introduces two new variables into the proof, `a : A` and `d : D`.  (The proof in *HTPI* uses a similar shortcut.  And we used a similar shortcut in the definitions of `inv R` and `comp R`, where the elements of these sets were written as ordered pairs.)

Here is the complete proof.

```lean
theorem Theorem_4_2_5_4 {A B C D : Type}
    (R : Set (A × B)) (S : Set (B × C)) (T : Set (C × D)) :
    comp T (comp S R) = comp (comp T S) R := by
  apply Set.ext
  fix (a, d) : A × D
  apply Iff.intro
  -- (→)
  assume h1 : (a, d) ∈ comp T (comp S R)
                     --Goal: (a, d) ∈ comp (comp T S) R
  define             --Goal: ∃ (x : B), (a, x) ∈ R ∧ (x, d) ∈ comp T S
  define at h1       --h1: ∃ (x : C), (a, x) ∈ comp S R ∧ (x, d) ∈ T
  obtain (c : C) (h2 : (a, c) ∈ comp S R ∧ (c, d) ∈ T) from h1
  have h3 : (a, c) ∈ comp S R := h2.left
  define at h3       --h3: ∃ (x : B), (a, x) ∈ R ∧ (x, c) ∈ S
  obtain (b : B) (h4 : (a, b) ∈ R ∧ (b, c) ∈ S) from h3
  apply Exists.intro b    --Goal: (a, b) ∈ R ∧ (b, d) ∈ comp T S
  apply And.intro h4.left --Goal: (b, d) ∈ comp T S
  define                  --Goal: ∃ (x : C), (b, x) ∈ S ∧ (x, d) ∈ T
  show ∃ (x : C), (b, x) ∈ S ∧ (x, d) ∈ T from
    Exists.intro c (And.intro h4.right h2.right)
  -- (←)
  assume h1 : (a, d) ∈ comp (comp T S) R
  define; define at h1
  obtain (b : B) (h2 : (a, b) ∈ R ∧ (b, d) ∈ comp T S) from h1
  have h3 : (b, d) ∈ comp T S := h2.right
  define at h3
  obtain (c : C) (h4 : (b, c) ∈ S ∧ (c, d) ∈ T) from h3
  apply Exists.intro c
  apply And.intro _ h4.right
  define
  show ∃ (x : B), (a, x) ∈ R ∧ (x, c) ∈ S from
    Exists.intro b (And.intro h2.left h4.left)
```

Of course, if you have trouble reading this proof, you can enter it into Lean and see how the tactic state changes over the course of the proof.

Here is a natural way to start the proof of part 5:

```lean
theorem Theorem_4_2_5_5 {A B C : Type}
    (R : Set (A × B)) (S : Set (B × C)) :
    inv (comp S R) = comp (inv R) (inv S) := by
  apply Set.ext
  fix (c, a) : C × A
  apply Iff.intro
  -- (→)
  assume h1 : (c, a) ∈ inv (comp S R) --Goal: (c, a) ∈ comp (inv R) (inv S)
  define at h1              --h1: ∃ x, (a, x) ∈ R ∧ (x, c) ∈ S
  define                    --Goal: ∃ x, (c, x) ∈ inv S ∧ (x, a) ∈ inv R
  obtain (b : B) (h2 : (a, b) ∈ R ∧ (b, c) ∈ S) from h1
  apply Exists.intro b      --Goal: (c, b) ∈ inv S ∧ (b, a) ∈ inv R
  define : (b, a) ∈ inv R
```

After the tactics `apply Set.ext` and `fix (c, a) : C × A`, the goal is `(c, a) ∈ inv (comp S R) ↔ (c, a) ∈ comp (inv R) (inv S)`.  For the proof of the left-to-right direction, we assume `h1 : (c, a) ∈ inv (comp S R)`, and we must prove `(c, a) ∈ comp (inv R) (inv S)`.  The definition of `h1` is an existential statement, so we apply existential instantiation to obtain `b : B` and `h2 : (a, b) ∈ R ∧ (b, c) ∈ S`.  The definition of the goal is also an existential statement, and after the tactic `apply And.intro b`, the goal is `(c, b) ∈ inv S ∧ (b, a) ∈ inv R`.  It looks like this goal will follow easily from `h2`, using the definitions of the inverses of `S` and `R`.

The tactic `define : (b, a) ∈ inv R` should rewrite the second half of the goal, using the definition of `inv R`.  You might expect the definition to be `(a, b) ∈ R`, but what the tactic produces is `R (a, b)`.  Usually, the `define` tactic does a good job of writing out definitions, but in this case it has let us down a bit.  The definition isn't wrong (explaining why would take us too far afield), but it isn't what we wanted.

Of course, we don't really need to use the `define` tactic---Lean will recognize that `(b, a) ∈ inv R` and `(a, b) ∈ R` are definitionally equally on its own.  But it would be nice if we could teach Lean to do a better job of writing out the definitions of inverses.  We can do that by proving a preliminary theorem before proving part 5 of Theorem 4.2.5:

```lean
theorem simp_inv
    {A B : Type} (R : Set (A × B)) (a : A) (b : B) :
    (b, a) ∈ inv R ↔ (a, b) ∈ R := by rfl
```

Now, any time we have a relation `R : Set (A × B)` and objects `a : A` and `b : B`, the expression `simp_inv R a b` will be a proof of the statement `(b, a) ∈ inv R ↔ (a, b) ∈ R`.  (Note that `A` and `B` are implicit arguments and don't need to be specified.)  And that means that the tactic `rewrite [simp_inv R a b]` will change `(b, a) ∈ inv R` to `(a, b) ∈ R`, exactly as we wanted.  In fact, as we've seen before, you can just write `rewrite [simp_inv]`, and Lean will figure out how to apply the theorem `simp_inv` to rewrite some part of the goal.

Returning to our proof of part 5 of Theorem 4.2.5, recall that after the step `apply Exists.intro b`, the goal is `(c, b) ∈ inv S ∧ (b, a) ∈ inv R`.  Rather than using the `define` tactic to write out the definitions of the inverses, we'll use the tactic `rewrite [simp_inv, simp_inv]`.  Why do we list `simp_inv` twice in the `rewrite` tactic?  When we ask Lean to use the theorem `simp_inv` as a rewriting rule, it figures out that `simp_inv S b c` is a proof of the statement `(c, b) ∈ inv S ↔ (b, c) ∈ S`, which can be used to rewrite the left half of the goal.  To rewrite the right half, we need a different application of the `simp_inv` theorem, `simp_inv R a b`.  So we have to ask Lean to apply the theorem a second time.  After the `rewrite` tactic, the goal is `(b, c) ∈ S ∧ (a, b) ∈ R`, which will follow easily from `h2`.

The rest of the proof of straightforward.  Here is the complete proof.

```lean
theorem Theorem_4_2_5_5 {A B C : Type}
    (R : Set (A × B)) (S : Set (B × C)) :
    inv (comp S R) = comp (inv R) (inv S) := by
  apply Set.ext
  fix (c, a) : C × A
  apply Iff.intro
  -- (→)
  assume h1 : (c, a) ∈ inv (comp S R) --Goal: (c, a) ∈ comp (inv R) (inv S)
  define at h1                 --h1: ∃ x, (a, x) ∈ R ∧ (x, c) ∈ S
  define                       --Goal: ∃ x, (c, x) ∈ inv S ∧ (x, a) ∈ inv R
  obtain (b : B) (h2 : (a, b) ∈ R ∧ (b, c) ∈ S) from h1
  apply Exists.intro b         --Goal: (c, b) ∈ inv S ∧ (b, a) ∈ inv R
  rewrite [simp_inv, simp_inv] --Goal: (b, c) ∈ S ∧ (a, b) ∈ R
  show (b, c) ∈ S ∧ (a, b) ∈ R from And.intro h2.right h2.left
  -- (←)
  assume h1 : (c, a) ∈ comp (inv R) (inv S)
  define at h1
  define
  obtain (b : B) (h2 : (c, b) ∈ inv S ∧ (b, a) ∈ inv R) from h1
  apply Exists.intro b
  rewrite [simp_inv, simp_inv] at h2
  show (a, b) ∈ R ∧ (b, c) ∈ S from And.intro h2.right h2.left
```

By the way, an alternative way to complete both directions of this proof would have been to apply the commutativity of "and".  See if you can guess the name of that theorem (you can use `#check` to confirm your guess) and apply it as a third rewriting rule in the `rewrite` steps.

### Exercises
```lean
theorem Exercise_4_2_9a {A B C : Type} (R : Set (A × B))
    (S : Set (B × C)) : Dom (comp S R) ⊆ Dom R := sorry

theorem Exercise_4_2_9b {A B C : Type} (R : Set (A × B))
    (S : Set (B × C)) : Ran R ⊆ Dom S → Dom (comp S R) = Dom R := sorry

--Fill in the blank to get a correct theorem and then prove the theorem
theorem Exercise_4_2_9c {A B C : Type} (R : Set (A × B))
    (S : Set (B × C)) : ___ → Ran (comp S R) = Ran S := sorry

theorem Exercise_4_2_12a {A B C : Type} (R : Set (A × B))
    (S T : Set (B × C)) : (comp S R) \ (comp T R) ⊆ comp (S \ T) R := sorry
```

Here is an incorrect theorem with an incorrect proof.

::: {.nthm arguments="Incorrect Theorem"}
Suppose $R$ is a relation from $A$ to $B$ and $S$ and $T$ are relations from $B$ to $C$.  Then $(S \setmin T) \circ R \subseteq (S \circ R) \setmin (T \circ R)$.
:::

::: {.incproof}
Suppose $(a, c) \in (S \setmin T) \circ R$. Then we can choose some $b \in B$ such that $(a, b) \in R$ and $(b, c) \in S \setmin T$, so $(b, c) \in S$ and $(b, c) \notin T$.  Since $(a, b) \in R$ and $(b, c) \in S$, $(a, c) \in S \circ R$.  Similarly, since $(a, b) \in R$ and $(b, c) \notin T$, $(a, c) \notin T \circ R$.  Therefore $(a, c) \in (S \circ R) \setmin (T \circ R)$.  Since $(a, c)$ was arbitrary, this shows that $(S \setmin T) \circ R \subseteq (S \circ R) \setmin (T \circ R)$.  [&nbsp;□]{.excl}\qedhere
:::

Find the mistake in the proof by attempting to write the proof in Lean:

```lean
--You won't be able to complete this proof
theorem Exercise_4_2_12b {A B C : Type} (R : Set (A × B))
    (S T : Set (B × C)) : comp (S \ T) R ⊆ (comp S R) \ (comp T R) := sorry
```

Is the following theorem correct?  Try to prove it in Lean.  If you can't prove it, see if you can find a counterexample.

```lean
--You might not be able to complete this proof
theorem Exercise_4_2_14c {A B C : Type} (R : Set (A × B))
    (S T : Set (B × C)) : comp (S ∩ T) R = (comp S R) ∩ (comp T R) := sorry

```

## 4.3. More About Relations

Section 4.3 of *HTPI* introduces new notation for working with relations.  If $R \subseteq A \times B$, $a \in A$, and $b \in B$, then *HTPI* introduces the notation $aRb$ as an alternative way of saying $(a, b) \in R$.

The notation we will use in Lean is slightly different.  Corresponding to the notation $aRb$ in *HTPI*, in Lean we will use the notation `R a b`.  And we cannot use this notation when `R` has type `Set (A × B)`.  Rather, we will need to introduce a new type for the variable `R` in the notation `R a b`.  The name we will use for this new type is `Rel A B`.  Thus, if `R` has type `Rel A B`, `a` has type `A`, and `b` has type `B`, then `R a b` is a proposition.  This should remind you of the way predicates work in Lean.  If we have `P : Pred A`, then we think of `P` as representing a property that an object of type `A` might have, and if we also have `a : A`, then `P a` is the proposition asserting that `a` has the property represented by `P`.  Similarly, if we have `R : Rel A B`, then we can think of `R` as representing a relationship that might hold between an object of type `A` and an object of type `B`, and if we also have `a : A` and `b : B`, then `R a b` is the proposition asserting that the relationship represented by `R` holds between `a` and `b`.

Notice that in *HTPI*, the same variable $R$ is used in both the notation $aRb$ and $(a, b) \in R$.  But in Lean, the notation `R a b` is used when `R` has type `Rel A B`, and the notation `(a, b) ∈ R` is used when `R` has type `Set (A × B)`.  The types `Rel A B` and `Set (A × B)` are different, so we cannot use the same variable `R` in the two notations.  However, there is a correspondence between the two types.  Suppose `R` has type `Rel A B`.  If we let `R'` denote the set of all ordered pairs `(a, b) : A × B` such that the proposition `R a b` is true, then `R'` has type `Set (A × B)`.  And there is then a simple relationship between `R` and `R'`: for any objects `a : A` and `b : B`, the propositions `R a b` and `(a, b) ∈ R'` are equivalent.  For our work in Lean, we will say that `R` is a *relation* from `A` to `B`, and `R'` is the *extension* of `R`.

We can define the extension of a relation, and state the correspondence between a relation and its extension, in Lean as follows:

```lean
def extension {A B : Type} (R : Rel A B) : Set (A × B) :=
    { (a, b) : A × B | R a b }

theorem simp_ext {A B : Type} (R : Rel A B) (a : A) (b : B) :
    (a, b) ∈ extension R ↔ R a b := by rfl
```

The rest of Chapter 4 of *HTPI* focuses on relations from a set to itself; in Lean, the corresponding idea is a relation from a type to itself.  If `A` is any type and `R` has type `Rel A A`, then we will say that `R` is a *binary relation on `A`*.  We define `BinRel A` to be the type of binary relations on `A`.  In other words, `BinRel A` is just an abbreviation for `Rel A A`.  If `R` is a binary relation on `A`, then we say that `R` is *reflexive* if for every `x` of type `A`, `R x x` holds.  It is *symmetric* if for all `x` and `y` of type `A`, if `R x y` then `R y x`.  And it is *transitive* if for all `x`, `y`, and `z` of type `A`, if `R x y` and `R y z` then `R x z`.  Of course, we can tell Lean about these definitions:

```lean
def reflexive {A : Type} (R : BinRel A) : Prop :=
    ∀ (x : A), R x x
def symmetric {A : Type} (R : BinRel A) : Prop :=
    ∀ (x y : A), R x y → R y x
def transitive {A : Type} (R : BinRel A) : Prop :=
    ∀ (x y z : A), R x y → R y z → R x z
``` 

Once again, we refer you to *HTPI* to see examples of these concepts, and we focus here on proving theorems about these concepts in Lean.  The main theorem about these concepts in Section 4.3 of *HTPI* is Theorem 4.3.4.  Here is what it says:

::: {.nthm arguments="Theorem 4.3.4"}
Suppose $R$ is a relation on a set $A$.

1.  $R$ is reflexive iff $\{(x, y) \in A \times A \mid x = y\} \subseteq R$.
2.  $R$ is symmetric iff $R = R^{-1}$.
3.  $R$ is transitive iff $R \circ R \subseteq R$.
:::

We can prove corresponding statements in Lean, but we'll have to be careful to distinguish between the types `BinRel A` and `Set (A × A)`.  In *HTPI*, each of the three statements in the theorem uses the same letter $R$ on both sides of the "iff", but we can't write the statements that way in Lean.  In each statement, the part before "iff" uses a concept that was defined for objects of type `BinRel A`, whereas the part after "iff" uses concepts that only make sense for objects of type `Set (A × A)`.  So we'll have to rephrase the statements by using the correspondence between a relation of type `BinRel A` and its extension, which has type `Set (A × A)`.  Here's the Lean theorem corresponding to statement 2 of Theorem 4.3.4:

```lean
theorem Theorem_4_3_4_2 {A : Type} (R : BinRel A) :
    symmetric R ↔ extension R = inv (extension R) := by
  apply Iff.intro
  -- (→)
  assume h1 : symmetric R
  define at h1             --h1: ∀ (x y : A), R x y → R y x
  apply Set.ext
  fix (a, b) : A × A
  show (a, b) ∈ extension R ↔ (a, b) ∈ inv (extension R) from
    calc
      (a, b) ∈ extension R ↔ R a b   := by rfl
      _ ↔ R b a                      := Iff.intro (h1 a b) (h1 b a)
      _ ↔ (a, b) ∈ inv (extension R) := by rfl
  -- (←)
  assume h1 : extension R = inv (extension R)
  define                   --Goal:  ∀ (x y : A), R x y → R y x
  fix a : A; fix b : A
  assume h2 : R a b        --Goal:  R b a
  rewrite [←simp_ext R, h1, simp_inv, simp_ext] at h2
  show R b a from h2
```

Note that at the end of the proof, we assume `h2 : R a b`, and our goal is `R b a`.  We convert `R a b` to `R b a` by a sequence of rewrites.  Applying the right-to-left direction of the theorem `simp_ext R a b` converts `R a b` to `(a, b) ∈ extension R`.  Then rewriting with `h1` converts this to `(a, b) ∈ inv (extension R)`, using `simp_inv (extension R) b a` converts this to `(b, a) ∈ extension R`, and finally `simp_ext R b a` produces `R b a`.  Usually we can leave out the arguments when we use a theorem as a rewriting rule, and Lean will figure them out for itself.  But in this case, if you try using `←simp_ext` as the first rewriting rule, you will see that Lean is unable to figure out that it should use the right-to-left direction of `simp_ext R a b`.  Supplying the first argument turns out to be enough of a hint for Lean to figure out the rest.  That's why our first rewriting rule is `←simp_ext R`.

We'll leave the proofs of the other two statements as exercises for you.

For any types `A` and `B`, if we want to define a particular relation `R` from `A` to `B`, we can do it by specifying, for any `a : A` and `b : B`, what proposition is represented by `R a b`.  For example, for any type `A`, we can define a relation `elementhood A` from `A` to `Set A` as follows:

```lean
def elementhood (A : Type) (a : A) (X : Set A) : Prop := a ∈ X
```

This definition says that if `A` is a type, `a` has type `A`, and `X` has type `Set A`, then `elementhood A a X` is the proposition `a ∈ X`.  Thus, if `elementhood A` is followed by objects of type `A` and `Set A`, the result is a proposition, so `elementhood A` is functioning as a relation from `A` to `Set A`.  For example, `elementhood Int` is a relation from integers to sets of integers, and `elementhood Int 6 { n : Int | ∃ (k : Int), n = 2 * k }` is the (true) statement that `6` is an element of the set of even integers.  (You are asked to prove it in the exercises.)

### Exercises

```lean
example : elementhood Int 6 { n : Int | ∃ (k : Int), n = 2 * k } := sorry

theorem Theorem_4_3_4_1 {A : Type} (R : BinRel A) :
    reflexive R ↔ { (x, y) : A × A | x = y } ⊆ extension R := sorry

theorem Theorem_4_3_4_3 {A : Type} (R : BinRel A) :
    transitive R ↔ comp (extension R) (extension R) ⊆ extension R := sorry
```

To state our remaining exercises, we'll need a definition.  If `R` has type `Set (A × B)`, then we define `relFromExt R` to be the relation whose extension is `R`.  A few simple theorems, which follow directly from the definition, clarify the meaning of `relFromExt R`.

```lean
def relFromExt {A B : Type}
    (R : Set (A × B)) (a : A) (b : B) : Prop := (a, b) ∈ R

theorem simp_relFromExt {A B : Type}
    (R : Set (A × B)) (a : A) (b : B) :
    relFromExt R a b ↔ (a, b) ∈ R := by rfl

example {A B : Type} (R : Rel A B) :
    relFromExt (extension R) = R := by rfl

example {A B : Type} (R : Set (A × B)) :
    extension (relFromExt R) = R := by rfl

theorem Exercise_4_3_12a {A : Type} (R : BinRel A) (h1 : reflexive R) :
    reflexive (relFromExt (inv (extension R))) := sorry

theorem Exercise_4_3_12c {A : Type} (R : BinRel A) (h1 : transitive R) :
    transitive (relFromExt (inv (extension R))) := sorry

theorem Exercise_4_3_18 {A : Type}
    (R S : BinRel A) (h1 : transitive R) (h2 : transitive S)
    (h3 : comp (extension S) (extension R) ⊆
        comp (extension R) (extension S)) :
    transitive (relFromExt (comp (extension R) (extension S))) := sorry
```

Are the following theorems correct?

```lean
--You might not be able to complete this proof
theorem Exercise_4_3_13b {A : Type}
    (R1 R2 : BinRel A) (h1 : symmetric R1) (h2 : symmetric R2) :
    symmetric (relFromExt ((extension R1) ∪ (extension R2))) := sorry

--You might not be able to complete this proof
theorem Exercise_4_3_13c {A : Type}
    (R1 R2 : BinRel A) (h1 : transitive R1) (h2 : transitive R2) :
    transitive (relFromExt ((extension R1) ∪ (extension R2))) := sorry
```

## 4.4. Ordering Relations

Section 4.4 of *HTPI* begins by defining several new concepts about binary relations.  Here are the definitions, written in Lean:

```lean
def antisymmetric {A : Type} (R : BinRel A) : Prop :=
    ∀ (x y : A), R x y → R y x → x = y

def partial_order {A : Type} (R : BinRel A) : Prop :=
    reflexive R ∧ transitive R ∧ antisymmetric R

def total_order {A : Type} (R : BinRel A) : Prop :=
    partial_order R ∧ ∀ (x y : A), R x y ∨ R y x
```

Example 4.4.3 in *HTPI* gives several examples of partial orders and total orders.  We'll give one of those examples here.  For any type `A`, we define `sub A` to be the subset relation on sets of objects of type `A`:

```lean
def sub (A : Type) (X Y : Set A) : Prop := X ⊆ Y
```

According to this definition, `sub A` is a binary relation on `Set A`, and for any two sets `X` and `Y` of type `Set A`, `sub A X Y` is the proposition `X ⊆ Y`.  We will leave it as an exercise for you to prove that `sub A` is a partial order on the type `Set A`.

Notice that `X ⊆ Y` could be thought of as expressing a sense in which `Y` is "at least as large as" than `X`.  Often, if `R` is a partial order on `A` and `a` and `b` have type `A`, then `R a b` can be thought of as meaning that `b` is in some sense "at least as large as" `a`.  Many of the concepts we study for partial and total orders are motivated by this intuition.



### Exercises

```lean
theorem Example_4_4_3_1 {A : Type} : partial_order (sub A) := sorry

```
