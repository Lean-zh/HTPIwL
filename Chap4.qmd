# Relations

## 4.1. Ordered Pairs and Cartesian Products

Section 4.1 of *How To Prove It* defines the *Cartesian product* $A \times B$ of two sets $A$ and $B$ to be the set of all ordered pairs $(a, b)$, where $a \in A$ and $b \in B$.  However, in Lean, Cartesian product is an operation on *types*, not sets.  If `A` and `B` are types, then `A × B` is the type of ordered pairs `(a, b)`, where `a` has type `A` and `b` has type `B`.  In other words, if you have `a : A` and `b : B`, then `(a, b)` is an object of type `A × B`.  There is also notation for the first and second coordinates of an ordered pair.  If `p` has type `A × B`, then `p.1` is the first coordinate of `p`, and `p.2` is the second coordinate.  In other words, `p = (p.1, p.2)`.  You can also use the notation `p.fst` for the first coordinate of `p` and `p.snd` for the second coordinate.

## 4.2.  Relations

Section 4.2 of *HTPI* defines a *relation from $A$ to $B$* to be a subset of $A \times B$.  In other words, if $R$ is a relation from $A$ to $B$, then $R$ is a set whose element are ordered pairs $(a, b)$, where $a \in A$ and $b \in B$.  We will see in the next section that in Lean, it is convenient to use a somewhat different definition of relations.  Nevertheless, we will take some time in this section to study sets of ordered pairs.  If `A` and `B` are types, and `R` is a set whose elements are ordered pairs `(a, b)`, where `a` has type `A` and `b` has type `B`, then `R` has type `Set (A × B)`.

Section 4.2 of *HTPI* discusses several concepts concerning relations.  Here is how these concepts are defined in *HTPI*:

::: {.ndfn arguments="Definition 4.2.3"}
Suppose $R$ is a relation from $A$ to $B$.  Then the *domain* of $R$ is the set

::: {.quote}
$\text{Dom}(R) = \{a \in A \mid \exists b \in B((a, b) \in R)\}$.
:::

The *range* of $R$ is the set

::: {.quote}
$\text{Ran}(R) = \{b \in B \mid \exists a \in A((a, b) \in R)\}$.
:::

The *inverse* of $R$ is the relation $R^{-1}$ from $B$ to $A$ define as follows:

::: {.quote}
$R^{-1} = \{(b, a) \in B \times A \mid (a, b) \in R\}$.
:::

Finally, suppose $R$ is a relation from $A$ to $B$ and $S$ is a relation from $B$ to $C$.  Then the *composition* of $S$ and $R$ is the relation $S \circ R$ from $A$ to $C$ defined as follows:

::: {.quote}
$S \circ R = \{(a, c) \in A \times C \mid \exists b \in B((a, b) \in R \text{ and } (b, c) \in S)\}$.
:::
:::

We can write corresponding definitions in Lean as follows:

```lean
def Dom {A B : Type} (R : Set (A × B)) : Set A :=
    {a : A | ∃ (b : B), (a, b) ∈ R}
def Ran {A B : Type} (R : Set (A × B)) : Set B :=
    {b : B | ∃ (a : A), (a, b) ∈ R}
def inv {A B : Type} (R : Set (A × B)) : Set (B × A) :=
    {p : B × A | (p.2, p.1) ∈ R}
def comp {A B C : Type} (S : Set (B × C)) (R : Set (A × B)) :
    Set (A × C) := {p : A × C | ∃ (b : B), (p.1, b) ∈ R ∧ (b, p.2) ∈ S}
```

Definitions in Lean are introduced with the keyword `def`.  In the definition of `Dom`, we have declared `A` and `B` to be implicit arguments.  That means that if we have `R : Set (A × B)`, then we can just write `Dom R` for the domain of `R`, and Lean will figure out for itself what `A` and `B` are.  The definition declares that `Dom R` has type `Set A`, and then it defines it to be the set of all objects `a` of type `A` such that there is some `b` of type `B` with `(a, b) ∈ R`.  This is a direct translation, into Lean's type-theory language, of the first part of Definition 4.2.3.  The other three definitions are similar; they define `Ran R` to be the range of `R`, `inv R` to be the inverse of `R`, and `comp S R` to be the composition of `S` and `R`.

Here is the main theorem about these concepts, as stated in *HTPI*:

::: {.nthm arguments="Theorem 4.2.5"}
Suppose $R$ is a relation from $A$ to $B$, $S$ is a relation from $B$ to $C$, and $T$ is a relation from $C$ to $D$.  Then:

1.  $(R^{-1})^{-1} = R$.
2.  $\mathrm{Dom}(R^{-1}) = \mathrm{Ran}(R)$.
3.  $\mathrm{Ran}(R^{-1}) = \mathrm{Dom}(R)$.
4.  $T \circ (S \circ R) = (T \circ S) \circ R$.
5.  $(S \circ R)^{-1} = R^{-1} \circ S^{-1}$.
:::

All five parts of this theorem follow directly from the definitions of the relevant concepts.  In fact, in the first three parts, Lean recognizes the two sides of the equation as being definitionally equal, and therefore the tactic `rfl` proves those parts:

```lean
theorem Theorem_4_2_5_1 {A B : Type}
    (R : Set (A × B)) : inv (inv R) = R := by rfl

theorem Theorem_4_2_5_2 {A B : Type}
    (R : Set (A × B)) : Dom (inv R) = Ran R := by rfl

theorem Theorem_4_2_5_3 {A B : Type}
    (R : Set (A × B)) : Ran (inv R) = Dom R := by rfl
```

The fourth part will take a little more work to prove.  Here is a natural way to start the proof:

```lean
theorem Theorem_4_2_5_4 {A B C : Type}
    (R : Set (A × B)) (S : Set (B × C)) (T : Set (C × D)) :
    comp T (comp S R) = comp (comp T S) R := by
  apply Set.ext
  fix (a, d) : A × D
  apply Iff.intro
  -- (→)
  assume h1 : (a, d) ∈ comp T (comp S R)
  define
```

After the `apply Set.ext` tactic, the goal is

::: {.quote}
`∀ (x : A × D), x ∈ comp T (comp S R) ↔ x ∈ comp (comp T S) R`
:::

The next step should be to introduce an arbitrary object of type `A × D`.  We could just call this object `x`, but Lean let's us use a shortcut here.  An object of type `A × D` must have the form of an ordered pair, where the first coordinate has type `A` and the second has type `D`.  So Lean let's us write it as an ordered pair right away.  That's what we've done in the second step, `fix (a, d) : A × D`.  This tactic introduces two new variables into the proof, `a : A` and `d : D`.  (The proof in *HTPI* uses a similar shortcut.)

After introducing the arbitrary ordered pair `(a, d)`, we must prove a biconditional statement, so we try to prove the two directions separately.  For the left-to-right direction, we assume `h1 : (a, d) ∈ comp T (comp S R)`, and we must prove `(a, d) ∈ comp (comp T S) R`.  When we ask Lean to write out the definition of the goal, the result is:

::: {.quote}
`∃ b, ((a, d).fst, b) ∈ R ∧ (b, (a, d).snd) ∈ comp T S`
:::

Usually, the `define` tactic does a good job of writing out definitions, but in this case it has let us down a bit.  The definition isn't wrong, but it's not written in the most convenient form.  We can improve on the result by using the tactics `define : (a, d).fst` and `define : (a, d).snd`, which put the goal into this form:

::: {.quote}
`∃ b, (a, b) ∈ R ∧ (b, d) ∈ comp T S`
:::

That solves the problem---this time.  But we're going to have to write out the definition of composition of relations several more times in this proof; will we have to fix Lean's awkward definition every time?

A better idea is to teach Lean to do a better job of using the definition of composition.  We can do that by proving a preliminary theorem before proving part 4 of Theorem 4.2.5:

```lean
theorem simp_comp
    {A B C : Type} (S : Set (B × C)) (R : Set (A × B)) (a : A) (c : C) :
    (a, c) ∈ comp S R ↔ ∃ (x : B), (a, x) ∈ R ∧ (x, c) ∈ S := by rfl
```

Now, any time we have relations `R : Set (A × B)` and `S : (B × C)`, and objects `a : A` and `c : C`, the expression `simp_comp S R a c` will be a proof of the statement `(a, c) ∈ comp S R ↔ ∃ (x : B), (a, x) ∈ R ∧ (x, c) ∈ S`.  And that means that the tactic `rewrite [simp_comp S R a c]` will change `(a, c) ∈ comp S R` to `∃ (x : B), (a, x) ∈ R ∧ (x, c) ∈ S`, exactly as we wanted.  In fact, as we've seen before, you can just write `rewrite [simp_comp]`, and Lean will figure out how to apply the theorem `simp_comp` to rewrite some part of the goal.

Actually, it's more convenient to do the rewriting before the step `apply Iff.intro`---otherwise we'd have to do it twice, once for each direction of the biconditional proof.  So now we start the proof like this:

```lean
theorem Theorem_4_2_5_4 {A B C : Type}
    (R : Set (A × B)) (S : Set (B × C)) (T : Set (C × D)) :
    comp T (comp S R) = comp (comp T S) R := by
  apply Set.ext
  fix (a, d) : A × D
  rewrite [simp_comp, simp_comp]
```

Why did we list `simp_comp` twice in the `rewrite` tactic?  After the step `fix (a, d) : A × D`, the goal is

::: {.quote}
`(a, d) ∈ comp T (comp S R) ↔ (a, d) ∈ comp (comp T S) R`
:::

When we ask Lean to use the theorem `simp_comp`, it figures out that `simp_comp T (comp S R) a d` is a proof of the statement

::: {.ind}
`(a, d) ∈ comp T (comp S R) ↔ ∃ (x : C), (a, x) ∈ comp S R ∧ (x, d) ∈ T`,
:::

which can be used to rewrite the left-hand side of the goal.  To rewrite the right-hand side, we need a different application of the `simp_comp` theorem, `simp_comp (comp T S) R a d`.  So we have to ask Lean to apply the theorem a second time.

Here is the complete proof.

```lean
theorem Theorem_4_2_5_4 {A B C : Type}
    (R : Set (A × B)) (S : Set (B × C)) (T : Set (C × D)) :
    comp T (comp S R) = comp (comp T S) R := by
  apply Set.ext
  fix (a, d) : A × D
  rewrite [simp_comp, simp_comp]
    --Goal:  (∃ (x : C), (a, x) ∈ comp S R ∧ (x, d) ∈ T) ↔
    --           ∃ (x : B), (a, x) ∈ R ∧ (x, d) ∈ comp T S
  apply Iff.intro
  -- (→)
  assume h1 : ∃ (x : C), (a, x) ∈ comp S R ∧ (x, d) ∈ T
  obtain (c : C) (h2 : (a, c) ∈ comp S R ∧ (c, d) ∈ T) from h1
  rewrite [simp_comp] at h2
    --h2: (∃ (x : B), (a, x) ∈ R ∧ (x, c) ∈ S) ∧ (c, d) ∈ T
  obtain (b : B) (h3 : (a, b) ∈ R ∧ (b, c) ∈ S) from h2.left
  apply Exists.intro b --Goal:  (a, b) ∈ R ∧ (b, d) ∈ comp T S
  apply And.intro h3.left
  rewrite [simp_comp]  --Goal:  ∃ (x : C), (b, x) ∈ S ∧ (x, d) ∈ T
  show ∃ (x : C), (b, x) ∈ S ∧ (x, d) ∈ T from
    Exists.intro c (And.intro h3.right h2.right)
  -- (←)
  assume h1 : ∃ (x : B), (a, x) ∈ R ∧ (x, d) ∈ comp T S
  obtain (b : B) (h2 : (a, b) ∈ R ∧ (b, d) ∈ comp T S) from h1
  rewrite [simp_comp] at h2
  obtain (c : C) (h3 : (b, c) ∈ S ∧ (c, d) ∈ T) from h2.right
  apply Exists.intro c
  apply And.intro _ h3.right
  rewrite [simp_comp]
  show ∃ (x : B), (a, x) ∈ R ∧ (x, c) ∈ S from
    Exists.intro b (And.intro h2.left h3.left)
```

Of course, if you have trouble reading this proof, you can type it into Lean and see how the tactic state changes over the course of the proof.